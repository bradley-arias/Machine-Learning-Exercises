{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxYASTXBDVc3"
      },
      "source": [
        "# CS 189 Homework 4 T-SNE\n",
        "**Note:** before starting this notebook, please save a copy of it to your own google drive, or your changes will not persist.\n",
        "\n",
        "In this problem, you will explore one way in which an ML engineer might try to interpret what the neural network they have just trained is doing. It turns out that t-SNE can come in handy here not just as a data visualization tool, but also as a *feature* visualization tool. Neural nets are, after all, trying to learn good features of the data for prediction.\n",
        "\n",
        "You will use scikit-learn's TSNE functionality for this problem, so it would be a good idea to look at that documentation. Your deliverables will be your code in this notebook as well as all plots that you produce here.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qoJVI0RCyaH"
      },
      "outputs": [],
      "source": [
        "# Imports for pytorch\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "import tqdm.notebook as tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gXlpSfT2A7I"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccIL1zFAkoVG"
      },
      "source": [
        "Place the `cifar10_classifier_large.pth` file provided in the root of the My Drive section of your Google Drive. If successfully done, the below `ls` command should work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXrTmGf8kcIb"
      },
      "outputs": [],
      "source": [
        "!ls /content/gdrive/MyDrive/cifar10_classifier_large.pth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmwd_kzNT-Cq"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device\", device)\n",
        "\n",
        "transform = torchvision.transforms.Compose(\n",
        "          [torchvision.transforms.ToTensor(),\n",
        "            torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "training_data = torchvision.datasets.CIFAR10(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform,\n",
        ")\n",
        "\n",
        "test_data = torchvision.datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "batch_size = 4\n",
        "trainloader = torch.utils.data.DataLoader(training_data, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "testloader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xY7rDFcg3og6"
      },
      "source": [
        "Feel free to visualize the data to get a sense of what the dataset looks like (note that the images have been normalized):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PNE-4LT3lx8"
      },
      "outputs": [],
      "source": [
        "images = [training_data[i][0] for i in range(9)]\n",
        "plt.imshow(torchvision.utils.make_grid(torch.stack(images), nrow=3, padding=5).numpy().transpose((1, 2, 0)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLDGeLcwK-IH"
      },
      "source": [
        "Part (a): Take the first 1000 images in the training dataset and perform t-SNE on the flattened images. Plot the t-SNE embeddings and color-code them by the class of each data point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4DyQNjKjlol"
      },
      "outputs": [],
      "source": [
        "### Part (a) ###\n",
        "### YOUR CODE HERE ###\n",
        "import matplotlib as mpl\n",
        "\n",
        "# set number of samples and perplexity\n",
        "samples = 1000\n",
        "perplexity = 40\n",
        "TSNE_data = TSNE(n_components=2, perplexity=perplexity, random_state=0)\n",
        "\n",
        "# create loaders\n",
        "training_subset = torch.utils.data.Subset(training_data, range(samples))\n",
        "trainloader_subset = torch.utils.data.DataLoader(training_subset, batch_size=batch_size)\n",
        "\n",
        "# take out the first 1000 images\n",
        "for data, labels in trainloader_subset:\n",
        "    break\n",
        "\n",
        "data = data.reshape(samples, -1) # flatten\n",
        "samples_embedded = TSNE_data.fit_transform(data) # T-SNE\n",
        "\n",
        "# visualize\n",
        "color_labels = np.unique(labels)\n",
        "cmap = mpl.colormaps[\"tab10\"].colors\n",
        "color_maps = {v: cmap[i] for i, v in enumerate(color_labels)}\n",
        "for p in color_labels:\n",
        "    plt.scatter(samples_embedded[labels==p, 0], samples_embedded[labels==p, 1], color=color_maps[p], s=20, marker='o', c=color_maps[p], label=f'class {p+1}', alpha=0.5)\n",
        "plt.legend()\n",
        "plt.title(f'T-SNE with {samples} samples and perplexity {perplexity}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLhDxz5OOS9l"
      },
      "source": [
        "Part (b): Find the test accuracy of the neural network provided.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJ32DyOT3NKB"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 128, 3, 1, 1)\n",
        "        self.bn1 = nn.BatchNorm2d(128)\n",
        "        self.conv2 = nn.Conv2d(128, 128, 3, 1, 1)\n",
        "        self.bn2 = nn.BatchNorm2d(128)\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv3 = nn.Conv2d(128, 256, 3, 1, 1)\n",
        "        self.bn3 = nn.BatchNorm2d(256)\n",
        "        self.conv4 = nn.Conv2d(256, 256, 3, 1, 1)\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool2 = nn.MaxPool2d(2)\n",
        "        self.linear1 = nn.Linear(256 * 8 * 8, 256)\n",
        "        self.bn_l1 = nn.BatchNorm1d(256)\n",
        "        self.linear2 = nn.Linear(256, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.bn1(F.relu(self.conv1(x)))\n",
        "        out = self.bn2(F.relu(self.conv2(out)))\n",
        "        out = self.pool1(out)\n",
        "        out = self.bn3(F.relu(self.conv3(out)))\n",
        "        out = self.bn4(F.relu(self.conv4(out)))\n",
        "        out = self.pool2(out)\n",
        "        out = torch.flatten(out, start_dim=1)\n",
        "        out = self.bn_l1(F.relu(self.linear1(out)))\n",
        "        out = self.linear2(out)\n",
        "        return out\n",
        "\n",
        "# Loading model\n",
        "net = Net().to(device)\n",
        "model_save_name = 'cifar10_classifier_large.pth'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" # Change path if necessary!\n",
        "net.load_state_dict(torch.load(path))\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZWMwUt6v116"
      },
      "outputs": [],
      "source": [
        "### Part (b) ###\n",
        "### YOUR CODE HERE ###\n",
        "# find the test accuracy of the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-mYYEb-OyOw"
      },
      "source": [
        "Part (c): For the following parts, we will make use of *hook* functions to save the outputs of particular layers of the model during a forward pass. We have provided a function below describing its usage. Use the function to obtain the set of outputs from net.conv3 for the first 1000 images of the training dataset as inputs. Then, run t-SNE on those outputs. Plot the t-SNE embeddings and color-code them by the class of each data point.\n",
        "\n",
        "For reference, the neural network layers are: \\\\\n",
        "net.conv1 \\\\\n",
        "net.conv2 \\\\\n",
        "net.conv3 \\\\\n",
        "net.conv4 \\\\\n",
        "net.linear1 \\\\\n",
        "net.linear2 \\\\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3GsVQfwz9kB"
      },
      "outputs": [],
      "source": [
        "class SaveFeatures():\n",
        "     features=None\n",
        "     def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n",
        "     def hook_fn(self, module, input, output): self.features = ((output.cpu()).data).numpy()\n",
        "     def remove(self): self.hook.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXnR0mopQmo_"
      },
      "outputs": [],
      "source": [
        "# Example: get_features_from_layer(net.conv1)\n",
        "def get_features_from_layer(layer):\n",
        "  activated_features = SaveFeatures(layer)\n",
        "  return activated_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ibj0WmYe0Egj"
      },
      "outputs": [],
      "source": [
        "### Part (c) ###\n",
        "### YOUR CODE HERE ###\n",
        "## Hint: Call get_features_from_layer() and use the 'features' attribute of the SaveFeatures class\n",
        "\n",
        "trainloader_subset = torch.utils.data.DataLoader(training_subset, batch_size=samples)\n",
        "conv3_features = get_features_from_layer(net.conv3)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in trainloader_subset:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        break\n",
        "\n",
        "layer_features = conv3_features.features\n",
        "flatten_features = layer_features.reshape(samples, -1)\n",
        "conv3_embedded = TSNE_data.fit_transform(flatten_features)\n",
        "\n",
        "# visualize\n",
        "labels = labels.cpu()\n",
        "color_labels = np.unique(labels)\n",
        "cmap = mpl.colormaps[\"tab10\"].colors\n",
        "color_maps = {v: cmap[i] for i, v in enumerate(color_labels)}\n",
        "\n",
        "for p in color_labels:\n",
        "    plt.scatter(conv3_embedded[labels==p, 0], conv3_embedded[labels==p, 1], color=color_maps[p], s=20, marker='o', c=color_maps[p], label=f'class {p+1}', alpha=0.5)\n",
        "\n",
        "plt.legend()\n",
        "plt.title(f'T-SNE of Conv3 Layer with {samples} samples and perplexity {perplexity}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKlwILWddvHl"
      },
      "source": [
        "Part (d): Do the same as part (c) except for the first and second linear layers of the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knjbrFnGeDGw"
      },
      "outputs": [],
      "source": [
        "### Part (d) ###\n",
        "### YOUR CODE HERE ###\n",
        "trainloader_subset = torch.utils.data.DataLoader(training_subset, batch_size=samples)\n",
        "conv1_features = get_features_from_layer(net.conv1)\n",
        "conv2_features = get_features_from_layer(net.conv2)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in trainloader_subset:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = net(images)\n",
        "        break\n",
        "\n",
        "features = [conv1_features, conv2_features]\n",
        "\n",
        "for feature in features:\n",
        "    layer_features = feature.features\n",
        "    flatten_features = layer_features.reshape(samples, -1)\n",
        "    embedded = TSNE_data.fit_transform(flatten_features)\n",
        "\n",
        "    # visualize\n",
        "    labels = labels.cpu()\n",
        "    color_labels = np.unique(labels)\n",
        "    cmap = mpl.colormaps[\"tab10\"].colors\n",
        "    color_maps = {v: cmap[i] for i, v in enumerate(color_labels)}\n",
        "    \n",
        "    for p in color_labels:\n",
        "        plt.scatter(embedded[labels==p, 0], embedded[labels==p, 1], color=color_maps[p], s=20, marker='o', c=color_maps[p], label=f'class {p+1}', alpha=0.5)\n",
        "    plt.legend()\n",
        "    layer_name = feature.hook\n",
        "    plt.title(f'T-SNE of {layer_name} Layer with {samples} samples and perplexity {perplexity}')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofNTv8Z57x1w"
      },
      "source": [
        "Congrats! You made it to the end."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
